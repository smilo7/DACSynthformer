experiment: "med_test_mine_02"

data_dir: "testdata/dac-train-mine"
data_frames: "testdata/dac-train-mine.xlsx"
validator_data_dir: "testdata/dac-val-mine"
validator_data_frames: "testdata/dac-val-mine.xlsx"


TransformerClass: "RopeCondDACTransformer" 
vocab_size: 1024 # Probably dont mess with this. Although maybe fun to explore the effect of vocab on the output of the model
num_tokens: 4

cond_params: 1 #1 (not counting the classes)
model_size: 256 # must be divisible by num_heads
# tblock_input_size: 35 #512  #embedding+conditioning vect

Ti: 86 # 172 #86
Tt: 430 # must match the length of the sequences in the batch IMPORTANT: THIS HAS TO MATCH THE LENGTH OF SEQUENCES IN THE DATA (HOW MANY FRAMES YOUR FILES ARE NUMBER OF FRAMES) IF YOU KEEP TO 5 SECOND SOUNDS DONT NEED TO UPDATE
batch_size: 4  #**


num_layers: 2 #**
num_heads: 8 #8 # 8 # embed_size must be divisible by num_heads
forward_expansion: 2 #4 #4
dropout_rate: 0.2
learning_rate: 0.0005

num_epochs: 300 ### 800 

ErrorLogRate: 2 #2 ### 10 How often we log the errors in prints and on the tensorboard
checkpoint_interval: 50 ###50 # 25 # save chekcpoints at this point

